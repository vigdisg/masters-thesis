{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF and MMDLoss classes are copied from https://github.com/yiftachbeer/mmd_loss_pytorch with some changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import lognorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RBF, laplacian and RQ kernels, MMD loss and energy distance loss functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(nn.Module):\n",
    "\n",
    "    def __init__(self, bandwidth=None): #bandwidth = sigma\n",
    "        super().__init__()\n",
    "        self.bandwidth_multipliers = torch.tensor([0.5, 1, 5, 10, 20, 40], dtype = torch.float32)\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "    def get_bandwidth(self): #if we want to scale the bandwiths\n",
    "        if self.bandwidth is None:\n",
    "            return 1\n",
    "        return self.bandwidth\n",
    "\n",
    "    def forward(self, X): #calculates the RBF kernel between each column in X\n",
    "        L2_distances = torch.cdist(X, X) ** 2 \n",
    "        return torch.exp(-0.5 * L2_distances[None, ...] / ((self.get_bandwidth() * self.bandwidth_multipliers)**2)[:, None, None]).sum(dim=0) - 6*torch.eye(len(X), dtype=torch.float32)\n",
    "        #dim 0 is the bandwidth dimension : the function returns sum of kernels with different bandwiths defined by self.bandwith_multipliers\n",
    "        #returns 0 on the diagonal line : dont care for kernel between data point and itself\n",
    "    \n",
    "class Laplacian(nn.Module):\n",
    "\n",
    "    def __init__(self, bandwidth=None): #bandwidth = gamma\n",
    "        super().__init__()\n",
    "        self.bandwidth_multipliers = torch.tensor([0.5, 1, 5, 10, 20, 40], dtype = torch.float32)\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "    def get_bandwidth(self): #if we want to scale the bandwiths\n",
    "        if self.bandwidth is None:\n",
    "            return 1\n",
    "        return self.bandwidth\n",
    "\n",
    "    def forward(self, X): #calculates the Laplacian kernel between each column in X\n",
    "        L1_distances = torch.cdist(X, X, p = 1) \n",
    "        return torch.exp(-L1_distances[None, ...] * (self.get_bandwidth() * self.bandwidth_multipliers)[:, None, None]).sum(dim=0) - 6*torch.eye(len(X), dtype=torch.float32)\n",
    "        #dim 0 is the bandwidth dimension : the function returns sum of kernels with different bandwiths defined by self.bandwith_multipliers\n",
    "        #returns 0 on the diagonal line : dont care for kernel between data point and itself\n",
    "\n",
    "class RQ(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = torch.tensor([0.25,0.5,1,2,5,10], dtype = torch.float32) #hyper-parameter alpha\n",
    "\n",
    "    def forward(self, X): #calculates the RQ kernel between each column in X\n",
    "        L2_distances = torch.cdist(X, X) ** 2 \n",
    "        return ((1+L2_distances[None, ...] / (2 * self.alpha)[:, None, None])**-self.alpha[:,None,None]).sum(dim=0) - 6*torch.eye(len(X), dtype=torch.float32)\n",
    "        #dim 0 is the dimension of alpha : the function returns sum of kernels with different alphas defined by self.alpha\n",
    "        #returns 0 on the diagonal line : dont care for kernel between data point and itself\n",
    "    \n",
    "class MMDLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel=RBF()):\n",
    "        super().__init__()\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def forward(self, X, Y): #calculates the unbiased empirical MMD between X and Y\n",
    "        K = self.kernel(torch.vstack([X, Y]))\n",
    "\n",
    "        X_size = X.shape[0]\n",
    "        Y_size = Y.shape[0]\n",
    "        XX = K[:X_size, :X_size].sum() / (X_size**2-X_size)\n",
    "        XY = K[:X_size, X_size:].mean()\n",
    "        YY = K[X_size:, X_size:].sum() / (Y_size**2-Y_size)\n",
    "        return XX - 2 * XY + YY \n",
    "\n",
    "class EnergyDistance(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X, Y): #calculates the unbiased empirical energy distance between X and Y\n",
    "        data = torch.vstack([X, Y])\n",
    "        L2_distances = torch.cdist(data, data)\n",
    "\n",
    "        X_size = X.shape[0]\n",
    "        Y_size = Y.shape[0]\n",
    "        XX = L2_distances[:X_size, :X_size].sum()/(X_size**2-X_size)\n",
    "        XY = L2_distances[:X_size, X_size:].mean()\n",
    "        YY = L2_distances[X_size:, X_size:].sum()/(Y_size**2-Y_size)\n",
    "        return -0.5*XX + XY -0.5*YY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "N = 20000\n",
    "x1 = np.random.uniform(0,1,N)\n",
    "x2 = np.random.uniform(0,1,N)\n",
    "i = [0]*N #stds\n",
    "for j in range(N):\n",
    "    if x1[j] > 0.5: i[j] = 1\n",
    "    else: i[j] = 0.5\n",
    "y = (x1 + x2)*np.exp(np.random.normal(0,i,N))\n",
    "X_input = np.column_stack((x1,x2))\n",
    "\n",
    "#create tensor data\n",
    "X_input = torch.tensor(X_input, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "#standardize\n",
    "X_means = X_input.mean(dim=0, keepdim=True)\n",
    "X_stds = X_input.std(dim=0, keepdim=True)\n",
    "X_input = (X_input) / X_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train MMD network with RBF kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.007421970367431641\n",
      "Finished epoch 1, latest loss 0.005133628845214844\n",
      "Finished epoch 2, latest loss -0.0009589195251464844\n",
      "Finished epoch 3, latest loss -0.0005993843078613281\n",
      "Finished epoch 4, latest loss -0.005067348480224609\n",
      "Finished epoch 5, latest loss 0.0045299530029296875\n",
      "Finished epoch 6, latest loss -0.0015788078308105469\n",
      "Finished epoch 7, latest loss -0.0021820068359375\n",
      "Finished epoch 8, latest loss -0.00327301025390625\n",
      "Finished epoch 9, latest loss -0.005383968353271484\n",
      "Finished epoch 10, latest loss -0.004042148590087891\n",
      "Finished epoch 11, latest loss -0.005469322204589844\n",
      "Finished epoch 12, latest loss 0.004057407379150391\n",
      "Finished epoch 13, latest loss -0.006428718566894531\n",
      "Finished epoch 14, latest loss -0.005052089691162109\n",
      "Finished epoch 15, latest loss 0.0034513473510742188\n",
      "Finished epoch 16, latest loss -0.006237506866455078\n",
      "Finished epoch 17, latest loss -0.005837917327880859\n",
      "Finished epoch 18, latest loss -0.0012578964233398438\n",
      "Finished epoch 19, latest loss -0.0025925636291503906\n",
      "Finished epoch 20, latest loss 0.0001010894775390625\n",
      "Finished epoch 21, latest loss -0.003972530364990234\n",
      "Finished epoch 22, latest loss -0.004505157470703125\n",
      "Finished epoch 23, latest loss -0.003806591033935547\n",
      "Finished epoch 24, latest loss -0.0036630630493164062\n",
      "Finished epoch 25, latest loss -0.003154754638671875\n",
      "Finished epoch 26, latest loss -0.004290580749511719\n",
      "Finished epoch 27, latest loss 0.005415201187133789\n",
      "Finished epoch 28, latest loss -0.003242969512939453\n",
      "Finished epoch 29, latest loss 0.002384185791015625\n",
      "Finished epoch 30, latest loss -0.001056671142578125\n",
      "Finished epoch 31, latest loss -0.004648685455322266\n",
      "Finished epoch 32, latest loss -0.0044422149658203125\n",
      "Finished epoch 33, latest loss -0.004098415374755859\n",
      "Finished epoch 34, latest loss -0.006775379180908203\n",
      "Finished epoch 35, latest loss -0.003155231475830078\n",
      "Finished epoch 36, latest loss -0.005334377288818359\n",
      "Finished epoch 37, latest loss -0.003536701202392578\n",
      "Finished epoch 38, latest loss -0.003895282745361328\n",
      "Finished epoch 39, latest loss -0.0016951560974121094\n",
      "Finished epoch 40, latest loss -0.004807949066162109\n",
      "Finished epoch 41, latest loss -0.004024505615234375\n",
      "Finished epoch 42, latest loss -0.00475311279296875\n",
      "Finished epoch 43, latest loss -0.005877017974853516\n",
      "Finished epoch 44, latest loss -0.0026082992553710938\n",
      "Finished epoch 45, latest loss -0.005139350891113281\n",
      "Finished epoch 46, latest loss -0.0037407875061035156\n",
      "Finished epoch 47, latest loss -0.004459381103515625\n",
      "Finished epoch 48, latest loss 0.0013918876647949219\n",
      "Finished epoch 49, latest loss -0.007124423980712891\n",
      "Finished epoch 50, latest loss -0.004247188568115234\n",
      "Finished epoch 51, latest loss -0.005194664001464844\n",
      "Finished epoch 52, latest loss -0.005288600921630859\n",
      "Finished epoch 53, latest loss 0.001007080078125\n",
      "Finished epoch 54, latest loss -0.004870891571044922\n",
      "Finished epoch 55, latest loss -0.0017170906066894531\n",
      "Finished epoch 56, latest loss -0.0030803680419921875\n",
      "Finished epoch 57, latest loss -0.004622936248779297\n",
      "Finished epoch 58, latest loss -0.005106925964355469\n",
      "Finished epoch 59, latest loss -0.006038188934326172\n",
      "Finished epoch 60, latest loss -0.004312038421630859\n",
      "Finished epoch 61, latest loss -0.005202293395996094\n",
      "Finished epoch 62, latest loss -0.0027942657470703125\n",
      "Finished epoch 63, latest loss -0.004591941833496094\n",
      "Finished epoch 64, latest loss -0.004283905029296875\n",
      "Finished epoch 65, latest loss -0.006256103515625\n",
      "Finished epoch 66, latest loss -0.0062427520751953125\n",
      "Finished epoch 67, latest loss -0.0035762786865234375\n",
      "Finished epoch 68, latest loss -0.0053081512451171875\n",
      "Finished epoch 69, latest loss -0.0011343955993652344\n",
      "Finished epoch 70, latest loss -0.003985881805419922\n",
      "Finished epoch 71, latest loss -0.0043354034423828125\n",
      "Finished epoch 72, latest loss -0.005656242370605469\n",
      "Finished epoch 73, latest loss -0.0010704994201660156\n",
      "Finished epoch 74, latest loss -0.0044918060302734375\n",
      "Finished epoch 75, latest loss -0.006324291229248047\n",
      "Finished epoch 76, latest loss -0.0004634857177734375\n",
      "Finished epoch 77, latest loss -0.005686759948730469\n",
      "Finished epoch 78, latest loss -0.0013017654418945312\n",
      "Finished epoch 79, latest loss -0.00354766845703125\n",
      "Finished epoch 80, latest loss -0.003567218780517578\n",
      "Finished epoch 81, latest loss -0.0019659996032714844\n",
      "Finished epoch 82, latest loss -0.005763530731201172\n",
      "Finished epoch 83, latest loss -0.004731178283691406\n",
      "Finished epoch 84, latest loss -0.003590106964111328\n",
      "Finished epoch 85, latest loss -0.005237102508544922\n",
      "Finished epoch 86, latest loss -0.004712581634521484\n",
      "Finished epoch 87, latest loss -0.004518032073974609\n",
      "Finished epoch 88, latest loss -0.001094818115234375\n",
      "Finished epoch 89, latest loss -0.006662607192993164\n",
      "Finished epoch 90, latest loss -0.0023708343505859375\n",
      "Finished epoch 91, latest loss -0.005181312561035156\n",
      "Finished epoch 92, latest loss -0.005615711212158203\n",
      "Finished epoch 93, latest loss -0.0027027130126953125\n",
      "Finished epoch 94, latest loss -0.004024028778076172\n",
      "Finished epoch 95, latest loss -0.005334377288818359\n",
      "Finished epoch 96, latest loss -0.0053958892822265625\n",
      "Finished epoch 97, latest loss -0.005705356597900391\n",
      "Finished epoch 98, latest loss -0.005370140075683594\n",
      "Finished epoch 99, latest loss -0.00408172607421875\n",
      "Finished epoch 100, latest loss -0.004742622375488281\n",
      "Finished epoch 101, latest loss -0.004502296447753906\n",
      "Finished epoch 102, latest loss -0.0031375885009765625\n",
      "Finished epoch 103, latest loss -0.0055389404296875\n",
      "Finished epoch 104, latest loss -0.0048885345458984375\n",
      "Finished epoch 105, latest loss -0.004467964172363281\n",
      "Finished epoch 106, latest loss -0.004418849945068359\n",
      "Finished epoch 107, latest loss -0.00551605224609375\n",
      "Finished epoch 108, latest loss -0.005626201629638672\n",
      "Finished epoch 109, latest loss -0.00024271011352539062\n",
      "Finished epoch 110, latest loss -0.004482269287109375\n",
      "Finished epoch 111, latest loss -0.005430698394775391\n",
      "Finished epoch 112, latest loss -0.004341602325439453\n",
      "Finished epoch 113, latest loss -0.007030010223388672\n",
      "Finished epoch 114, latest loss -0.004834175109863281\n",
      "Finished epoch 115, latest loss -0.0030488967895507812\n",
      "Finished epoch 116, latest loss -0.005411624908447266\n",
      "Finished epoch 117, latest loss -0.005396842956542969\n",
      "Finished epoch 118, latest loss -0.006036281585693359\n",
      "Finished epoch 119, latest loss -0.003582000732421875\n",
      "Finished epoch 120, latest loss -0.0026922225952148438\n",
      "Finished epoch 121, latest loss -0.006346225738525391\n",
      "Finished epoch 122, latest loss 0.0026497840881347656\n",
      "Finished epoch 123, latest loss -0.0031337738037109375\n",
      "Finished epoch 124, latest loss -0.006503582000732422\n",
      "Finished epoch 125, latest loss -0.005043983459472656\n",
      "Finished epoch 126, latest loss -0.006284236907958984\n",
      "Finished epoch 127, latest loss -0.005393028259277344\n",
      "Finished epoch 128, latest loss -0.0036363601684570312\n",
      "Finished epoch 129, latest loss -0.005814075469970703\n",
      "Finished epoch 130, latest loss -0.005061149597167969\n",
      "Finished epoch 131, latest loss -0.005707740783691406\n",
      "Finished epoch 132, latest loss -0.0040283203125\n",
      "Finished epoch 133, latest loss -0.005877971649169922\n",
      "Finished epoch 134, latest loss -0.0012478828430175781\n",
      "Finished epoch 135, latest loss -0.004831790924072266\n",
      "Finished epoch 136, latest loss -0.005992412567138672\n",
      "Finished epoch 137, latest loss -0.005504131317138672\n",
      "Finished epoch 138, latest loss -0.004897594451904297\n",
      "Finished epoch 139, latest loss -0.005257844924926758\n",
      "Finished epoch 140, latest loss -0.005305290222167969\n",
      "Finished epoch 141, latest loss -0.005480766296386719\n",
      "Finished epoch 142, latest loss -0.004383087158203125\n",
      "Finished epoch 143, latest loss -0.005298614501953125\n",
      "Finished epoch 144, latest loss -0.005113124847412109\n",
      "Finished epoch 145, latest loss -0.005736351013183594\n",
      "Finished epoch 146, latest loss -0.0020804405212402344\n",
      "Finished epoch 147, latest loss -0.004303932189941406\n",
      "Finished epoch 148, latest loss -0.004178047180175781\n",
      "Finished epoch 149, latest loss -0.0032787322998046875\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "N_input = 100 #dimension of uniformly sampled input\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(X_input.shape[1]+N_input, 200)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(200, 200)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(200, 100)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.hidden4 = nn.Linear(100, 100)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act4(self.hidden4(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "model = network()\n",
    "\n",
    "loss_fn = MMDLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 150 \n",
    "batch_size = 400 \n",
    "\n",
    "#training loop\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    #shuffle training data:\n",
    "    shuffle = torch.randperm(len(y))\n",
    "    y = y[shuffle]\n",
    "    X_input = X_input[shuffle]\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        Xbatch = X_input[i:i+batch_size] #predictors\n",
    "        x = np.random.uniform(-0.5,0.5,batch_size*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(batch_size, N_input)\n",
    "        X_model = torch.column_stack([Xbatch,x]) #model inputs\n",
    "        y_pred = model(X_model) #generated data\n",
    "        ybatch = y[i:i+batch_size] #real data\n",
    "        pred = torch.column_stack([Xbatch,y_pred])\n",
    "        real = torch.column_stack([Xbatch,ybatch])\n",
    "        loss = loss_fn(pred, real)\n",
    "        optimizer.zero_grad() #reset gradient\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer.step() #optimizer iteration\n",
    "        losses.append(loss)\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MMD network with laplacian kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss -0.001164466142654419\n",
      "Finished epoch 1, latest loss -0.00308990478515625\n",
      "Finished epoch 2, latest loss -0.0022985339164733887\n",
      "Finished epoch 3, latest loss -0.0016699433326721191\n",
      "Finished epoch 4, latest loss -0.006467670202255249\n",
      "Finished epoch 5, latest loss -0.000380784273147583\n",
      "Finished epoch 6, latest loss -0.00399431586265564\n",
      "Finished epoch 7, latest loss -0.004797816276550293\n",
      "Finished epoch 8, latest loss -0.005835175514221191\n",
      "Finished epoch 9, latest loss -0.000730663537979126\n",
      "Finished epoch 10, latest loss -0.007048547267913818\n",
      "Finished epoch 11, latest loss -0.006581634283065796\n",
      "Finished epoch 12, latest loss -0.003927737474441528\n",
      "Finished epoch 13, latest loss -0.006373554468154907\n",
      "Finished epoch 14, latest loss -0.00569605827331543\n",
      "Finished epoch 15, latest loss -0.006645381450653076\n",
      "Finished epoch 16, latest loss -0.004202753305435181\n",
      "Finished epoch 17, latest loss -0.006213933229446411\n",
      "Finished epoch 18, latest loss -0.0018954575061798096\n",
      "Finished epoch 19, latest loss -0.006487369537353516\n",
      "Finished epoch 20, latest loss -0.004756838083267212\n",
      "Finished epoch 21, latest loss -0.006116598844528198\n",
      "Finished epoch 22, latest loss -0.00599980354309082\n",
      "Finished epoch 23, latest loss -0.004646182060241699\n",
      "Finished epoch 24, latest loss -0.00566864013671875\n",
      "Finished epoch 25, latest loss -0.0032957494258880615\n",
      "Finished epoch 26, latest loss -0.005508601665496826\n",
      "Finished epoch 27, latest loss -0.004136204719543457\n",
      "Finished epoch 28, latest loss -0.006264299154281616\n",
      "Finished epoch 29, latest loss -0.0044754743576049805\n",
      "Finished epoch 30, latest loss -0.007530182600021362\n",
      "Finished epoch 31, latest loss -0.006062746047973633\n",
      "Finished epoch 32, latest loss -0.007032930850982666\n",
      "Finished epoch 33, latest loss -0.007486253976821899\n",
      "Finished epoch 34, latest loss -0.004599064588546753\n",
      "Finished epoch 35, latest loss -0.006447136402130127\n",
      "Finished epoch 36, latest loss -0.005819737911224365\n",
      "Finished epoch 37, latest loss -0.005064100027084351\n",
      "Finished epoch 38, latest loss -0.006192833185195923\n",
      "Finished epoch 39, latest loss -0.004784375429153442\n",
      "Finished epoch 40, latest loss -0.006750762462615967\n",
      "Finished epoch 41, latest loss -0.004311710596084595\n",
      "Finished epoch 42, latest loss -0.006937891244888306\n",
      "Finished epoch 43, latest loss -0.005771249532699585\n",
      "Finished epoch 44, latest loss -0.006573349237442017\n",
      "Finished epoch 45, latest loss -0.0049571692943573\n",
      "Finished epoch 46, latest loss -0.003830432891845703\n",
      "Finished epoch 47, latest loss -0.00413358211517334\n",
      "Finished epoch 48, latest loss -0.0056600868701934814\n",
      "Finished epoch 49, latest loss -0.007149606943130493\n",
      "Finished epoch 50, latest loss -0.007387518882751465\n",
      "Finished epoch 51, latest loss -0.005004554986953735\n",
      "Finished epoch 52, latest loss -0.0046125054359436035\n",
      "Finished epoch 53, latest loss -0.007199972867965698\n",
      "Finished epoch 54, latest loss -0.006053745746612549\n",
      "Finished epoch 55, latest loss -0.0055481791496276855\n",
      "Finished epoch 56, latest loss -0.0068337321281433105\n",
      "Finished epoch 57, latest loss -0.005610346794128418\n",
      "Finished epoch 58, latest loss -0.006684690713882446\n",
      "Finished epoch 59, latest loss -0.005626320838928223\n",
      "Finished epoch 60, latest loss -0.00652804970741272\n",
      "Finished epoch 61, latest loss -0.00505712628364563\n",
      "Finished epoch 62, latest loss -0.007225096225738525\n",
      "Finished epoch 63, latest loss -0.0066110193729400635\n",
      "Finished epoch 64, latest loss -0.006747305393218994\n",
      "Finished epoch 65, latest loss -0.007220864295959473\n",
      "Finished epoch 66, latest loss -0.006280392408370972\n",
      "Finished epoch 67, latest loss -0.007485300302505493\n",
      "Finished epoch 68, latest loss -0.0063755810260772705\n",
      "Finished epoch 69, latest loss -0.0052339136600494385\n",
      "Finished epoch 70, latest loss -0.006823241710662842\n",
      "Finished epoch 71, latest loss -0.007354527711868286\n",
      "Finished epoch 72, latest loss -0.006762444972991943\n",
      "Finished epoch 73, latest loss -0.00640636682510376\n",
      "Finished epoch 74, latest loss -0.007396131753921509\n",
      "Finished epoch 75, latest loss -0.005921870470046997\n",
      "Finished epoch 76, latest loss -0.007723122835159302\n",
      "Finished epoch 77, latest loss -0.0071273744106292725\n",
      "Finished epoch 78, latest loss -0.005502551794052124\n",
      "Finished epoch 79, latest loss -0.005064040422439575\n",
      "Finished epoch 80, latest loss -0.004465639591217041\n",
      "Finished epoch 81, latest loss -0.005312711000442505\n",
      "Finished epoch 82, latest loss -0.006778687238693237\n",
      "Finished epoch 83, latest loss -0.005696386098861694\n",
      "Finished epoch 84, latest loss -0.0071579813957214355\n",
      "Finished epoch 85, latest loss -0.006418824195861816\n",
      "Finished epoch 86, latest loss -0.007152080535888672\n",
      "Finished epoch 87, latest loss -0.006875067949295044\n",
      "Finished epoch 88, latest loss -0.00704646110534668\n",
      "Finished epoch 89, latest loss -0.005962491035461426\n",
      "Finished epoch 90, latest loss -0.0067091286182403564\n",
      "Finished epoch 91, latest loss -0.0066308677196502686\n",
      "Finished epoch 92, latest loss -0.007214933633804321\n",
      "Finished epoch 93, latest loss -0.006589263677597046\n",
      "Finished epoch 94, latest loss -0.00689852237701416\n",
      "Finished epoch 95, latest loss -0.0064848363399505615\n",
      "Finished epoch 96, latest loss -0.005334198474884033\n",
      "Finished epoch 97, latest loss -0.0068496763706207275\n",
      "Finished epoch 98, latest loss -0.006201654672622681\n",
      "Finished epoch 99, latest loss -0.006681650876998901\n",
      "Finished epoch 100, latest loss -0.006167024374008179\n",
      "Finished epoch 101, latest loss -0.006140202283859253\n",
      "Finished epoch 102, latest loss -0.005886763334274292\n",
      "Finished epoch 103, latest loss -0.007037043571472168\n",
      "Finished epoch 104, latest loss -0.006765902042388916\n",
      "Finished epoch 105, latest loss -0.006825149059295654\n",
      "Finished epoch 106, latest loss -0.006901174783706665\n",
      "Finished epoch 107, latest loss -0.006804674863815308\n",
      "Finished epoch 108, latest loss -0.006772518157958984\n",
      "Finished epoch 109, latest loss -0.0052263736724853516\n",
      "Finished epoch 110, latest loss -0.006881922483444214\n",
      "Finished epoch 111, latest loss -0.006249904632568359\n",
      "Finished epoch 112, latest loss -0.0012389421463012695\n",
      "Finished epoch 113, latest loss -0.004699110984802246\n",
      "Finished epoch 114, latest loss -0.006261676549911499\n",
      "Finished epoch 115, latest loss -0.006485015153884888\n",
      "Finished epoch 116, latest loss -0.006955057382583618\n",
      "Finished epoch 117, latest loss -0.006574779748916626\n",
      "Finished epoch 118, latest loss -0.003141850233078003\n",
      "Finished epoch 119, latest loss -0.006074100732803345\n",
      "Finished epoch 120, latest loss -0.0062770843505859375\n",
      "Finished epoch 121, latest loss -0.00742262601852417\n",
      "Finished epoch 122, latest loss -0.00677606463432312\n",
      "Finished epoch 123, latest loss -0.006759285926818848\n",
      "Finished epoch 124, latest loss -0.007399648427963257\n",
      "Finished epoch 125, latest loss -0.0037609636783599854\n",
      "Finished epoch 126, latest loss -0.0067993998527526855\n",
      "Finished epoch 127, latest loss -0.006016135215759277\n",
      "Finished epoch 128, latest loss -0.0073077380657196045\n",
      "Finished epoch 129, latest loss -0.005880266427993774\n",
      "Finished epoch 130, latest loss -0.006453573703765869\n",
      "Finished epoch 131, latest loss -0.006720840930938721\n",
      "Finished epoch 132, latest loss -0.007526904344558716\n",
      "Finished epoch 133, latest loss -0.00546225905418396\n",
      "Finished epoch 134, latest loss -0.006644219160079956\n",
      "Finished epoch 135, latest loss -0.006023406982421875\n",
      "Finished epoch 136, latest loss -0.006669491529464722\n",
      "Finished epoch 137, latest loss -0.008089184761047363\n",
      "Finished epoch 138, latest loss -0.0066242516040802\n",
      "Finished epoch 139, latest loss -0.006318926811218262\n",
      "Finished epoch 140, latest loss -0.007608264684677124\n",
      "Finished epoch 141, latest loss -0.007044762372970581\n",
      "Finished epoch 142, latest loss -0.005461543798446655\n",
      "Finished epoch 143, latest loss -0.006618529558181763\n",
      "Finished epoch 144, latest loss -0.007939666509628296\n",
      "Finished epoch 145, latest loss -0.006691038608551025\n",
      "Finished epoch 146, latest loss -0.007315993309020996\n",
      "Finished epoch 147, latest loss -0.007018446922302246\n",
      "Finished epoch 148, latest loss -0.007050603628158569\n",
      "Finished epoch 149, latest loss -0.006424367427825928\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "    \n",
    "model_Laplacian = network()\n",
    "\n",
    "loss_fn_Laplacian = MMDLoss(kernel=Laplacian())\n",
    "optimizer_Laplacian = optim.RMSprop(model_Laplacian.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 150 \n",
    "batch_size = 400 \n",
    "\n",
    "#training loop\n",
    "for epoch in range(n_epochs):\n",
    "    #shuffle training data:\n",
    "    shuffle = torch.randperm(len(y))\n",
    "    y = y[shuffle]\n",
    "    X_input = X_input[shuffle]\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        Xbatch = X_input[i:i+batch_size] #predictors\n",
    "        x = np.random.uniform(-0.5,0.5,batch_size*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(batch_size, N_input)\n",
    "        X_model = torch.column_stack([Xbatch,x]) #model inputs\n",
    "        y_pred = model_Laplacian(X_model) #generated data\n",
    "        ybatch = y[i:i+batch_size] #real data\n",
    "        pred = torch.column_stack([Xbatch,y_pred])\n",
    "        real = torch.column_stack([Xbatch,ybatch])\n",
    "        loss = loss_fn_Laplacian(pred, real)\n",
    "        optimizer_Laplacian.zero_grad() #reset gradient\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer_Laplacian.step() #optimizer iteration\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MMD network with RQ kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss -0.0014243125915527344\n",
      "Finished epoch 1, latest loss 0.007174491882324219\n",
      "Finished epoch 2, latest loss 0.0032112598419189453\n",
      "Finished epoch 3, latest loss -0.008359670639038086\n",
      "Finished epoch 4, latest loss -0.008797526359558105\n",
      "Finished epoch 5, latest loss -0.0008671283721923828\n",
      "Finished epoch 6, latest loss -0.009828567504882812\n",
      "Finished epoch 7, latest loss -0.007536411285400391\n",
      "Finished epoch 8, latest loss -0.005490779876708984\n",
      "Finished epoch 9, latest loss -0.012887239456176758\n",
      "Finished epoch 10, latest loss -0.009400367736816406\n",
      "Finished epoch 11, latest loss 0.0016214847564697266\n",
      "Finished epoch 12, latest loss 0.002850055694580078\n",
      "Finished epoch 13, latest loss -0.007468104362487793\n",
      "Finished epoch 14, latest loss -0.008979558944702148\n",
      "Finished epoch 15, latest loss 0.012654542922973633\n",
      "Finished epoch 16, latest loss -0.011616945266723633\n",
      "Finished epoch 17, latest loss -0.010430574417114258\n",
      "Finished epoch 18, latest loss -0.012375116348266602\n",
      "Finished epoch 19, latest loss -0.0066034793853759766\n",
      "Finished epoch 20, latest loss -0.011720418930053711\n",
      "Finished epoch 21, latest loss -0.003899097442626953\n",
      "Finished epoch 22, latest loss -0.006038188934326172\n",
      "Finished epoch 23, latest loss -0.009628534317016602\n",
      "Finished epoch 24, latest loss -0.008099079132080078\n",
      "Finished epoch 25, latest loss -0.010756969451904297\n",
      "Finished epoch 26, latest loss 0.003076791763305664\n",
      "Finished epoch 27, latest loss -0.012342214584350586\n",
      "Finished epoch 28, latest loss -0.00977182388305664\n",
      "Finished epoch 29, latest loss -0.004548549652099609\n",
      "Finished epoch 30, latest loss -0.007329702377319336\n",
      "Finished epoch 31, latest loss -0.010647296905517578\n",
      "Finished epoch 32, latest loss -0.00015878677368164062\n",
      "Finished epoch 33, latest loss -0.011046886444091797\n",
      "Finished epoch 34, latest loss -0.006865978240966797\n",
      "Finished epoch 35, latest loss -0.012229681015014648\n",
      "Finished epoch 36, latest loss -0.011214494705200195\n",
      "Finished epoch 37, latest loss -0.013087272644042969\n",
      "Finished epoch 38, latest loss -0.01182866096496582\n",
      "Finished epoch 39, latest loss -0.012342453002929688\n",
      "Finished epoch 40, latest loss -0.010784387588500977\n",
      "Finished epoch 41, latest loss -0.012304544448852539\n",
      "Finished epoch 42, latest loss -0.012927770614624023\n",
      "Finished epoch 43, latest loss -0.010118484497070312\n",
      "Finished epoch 44, latest loss -0.014355659484863281\n",
      "Finished epoch 45, latest loss -0.0054552555084228516\n",
      "Finished epoch 46, latest loss -0.014339685440063477\n",
      "Finished epoch 47, latest loss -0.014824151992797852\n",
      "Finished epoch 48, latest loss -0.01176142692565918\n",
      "Finished epoch 49, latest loss -0.008019208908081055\n",
      "Finished epoch 50, latest loss -0.009578704833984375\n",
      "Finished epoch 51, latest loss -0.011414766311645508\n",
      "Finished epoch 52, latest loss -0.013193368911743164\n",
      "Finished epoch 53, latest loss -0.005042314529418945\n",
      "Finished epoch 54, latest loss -0.011353015899658203\n",
      "Finished epoch 55, latest loss -0.009364128112792969\n",
      "Finished epoch 56, latest loss -0.0072174072265625\n",
      "Finished epoch 57, latest loss -0.01270747184753418\n",
      "Finished epoch 58, latest loss -0.01045072078704834\n",
      "Finished epoch 59, latest loss -0.013056039810180664\n",
      "Finished epoch 60, latest loss -0.010617256164550781\n",
      "Finished epoch 61, latest loss -0.004441976547241211\n",
      "Finished epoch 62, latest loss -0.013491153717041016\n",
      "Finished epoch 63, latest loss -0.005790233612060547\n",
      "Finished epoch 64, latest loss -0.008418560028076172\n",
      "Finished epoch 65, latest loss -0.013379335403442383\n",
      "Finished epoch 66, latest loss -0.006893634796142578\n",
      "Finished epoch 67, latest loss -0.008559465408325195\n",
      "Finished epoch 68, latest loss -0.011914730072021484\n",
      "Finished epoch 69, latest loss -0.014931917190551758\n",
      "Finished epoch 70, latest loss -0.009912967681884766\n",
      "Finished epoch 71, latest loss -0.013456344604492188\n",
      "Finished epoch 72, latest loss -0.009251952171325684\n",
      "Finished epoch 73, latest loss -0.0012958049774169922\n",
      "Finished epoch 74, latest loss -0.01109933853149414\n",
      "Finished epoch 75, latest loss -0.013713598251342773\n",
      "Finished epoch 76, latest loss -0.007484912872314453\n",
      "Finished epoch 77, latest loss -0.006543636322021484\n",
      "Finished epoch 78, latest loss -0.007872819900512695\n",
      "Finished epoch 79, latest loss -0.010537385940551758\n",
      "Finished epoch 80, latest loss -0.011387348175048828\n",
      "Finished epoch 81, latest loss -0.012847661972045898\n",
      "Finished epoch 82, latest loss -0.005381584167480469\n",
      "Finished epoch 83, latest loss -0.009183645248413086\n",
      "Finished epoch 84, latest loss -0.011918067932128906\n",
      "Finished epoch 85, latest loss -0.006304502487182617\n",
      "Finished epoch 86, latest loss -0.011887311935424805\n",
      "Finished epoch 87, latest loss -0.006564617156982422\n",
      "Finished epoch 88, latest loss -0.011469841003417969\n",
      "Finished epoch 89, latest loss -0.010504961013793945\n",
      "Finished epoch 90, latest loss -0.009224176406860352\n",
      "Finished epoch 91, latest loss -0.012699604034423828\n",
      "Finished epoch 92, latest loss -0.0138702392578125\n",
      "Finished epoch 93, latest loss -0.011508703231811523\n",
      "Finished epoch 94, latest loss -0.014906644821166992\n",
      "Finished epoch 95, latest loss -0.01435708999633789\n",
      "Finished epoch 96, latest loss -0.012665510177612305\n",
      "Finished epoch 97, latest loss -0.013545036315917969\n",
      "Finished epoch 98, latest loss -0.009057044982910156\n",
      "Finished epoch 99, latest loss -0.0046045780181884766\n",
      "Finished epoch 100, latest loss -0.010656356811523438\n",
      "Finished epoch 101, latest loss -0.0064694881439208984\n",
      "Finished epoch 102, latest loss -0.005595207214355469\n",
      "Finished epoch 103, latest loss -0.004950523376464844\n",
      "Finished epoch 104, latest loss -0.012788057327270508\n",
      "Finished epoch 105, latest loss -0.013643503189086914\n",
      "Finished epoch 106, latest loss -0.01175832748413086\n",
      "Finished epoch 107, latest loss -0.011490583419799805\n",
      "Finished epoch 108, latest loss -0.01218557357788086\n",
      "Finished epoch 109, latest loss -0.010931968688964844\n",
      "Finished epoch 110, latest loss -0.013755559921264648\n",
      "Finished epoch 111, latest loss -0.013574838638305664\n",
      "Finished epoch 112, latest loss -0.014245748519897461\n",
      "Finished epoch 113, latest loss -0.01051950454711914\n",
      "Finished epoch 114, latest loss -0.01513814926147461\n",
      "Finished epoch 115, latest loss -0.006339073181152344\n",
      "Finished epoch 116, latest loss -0.009775400161743164\n",
      "Finished epoch 117, latest loss -0.010751485824584961\n",
      "Finished epoch 118, latest loss -0.00975489616394043\n",
      "Finished epoch 119, latest loss -0.008469104766845703\n",
      "Finished epoch 120, latest loss -0.0075751543045043945\n",
      "Finished epoch 121, latest loss -0.014850854873657227\n",
      "Finished epoch 122, latest loss -0.011774778366088867\n",
      "Finished epoch 123, latest loss -0.012569904327392578\n",
      "Finished epoch 124, latest loss -0.01008307933807373\n",
      "Finished epoch 125, latest loss -0.013233661651611328\n",
      "Finished epoch 126, latest loss -0.01102900505065918\n",
      "Finished epoch 127, latest loss -0.0007138252258300781\n",
      "Finished epoch 128, latest loss -0.013103246688842773\n",
      "Finished epoch 129, latest loss -0.013040781021118164\n",
      "Finished epoch 130, latest loss -0.0074005126953125\n",
      "Finished epoch 131, latest loss -0.007953643798828125\n",
      "Finished epoch 132, latest loss -0.012562274932861328\n",
      "Finished epoch 133, latest loss -0.014245986938476562\n",
      "Finished epoch 134, latest loss -0.004979610443115234\n",
      "Finished epoch 135, latest loss -0.012870311737060547\n",
      "Finished epoch 136, latest loss -0.011193037033081055\n",
      "Finished epoch 137, latest loss -0.01130986213684082\n",
      "Finished epoch 138, latest loss -0.014118671417236328\n",
      "Finished epoch 139, latest loss -0.011684656143188477\n",
      "Finished epoch 140, latest loss -0.013855218887329102\n",
      "Finished epoch 141, latest loss -0.009504318237304688\n",
      "Finished epoch 142, latest loss -0.012181282043457031\n",
      "Finished epoch 143, latest loss -0.011712789535522461\n",
      "Finished epoch 144, latest loss -0.01210927963256836\n",
      "Finished epoch 145, latest loss -0.00901174545288086\n",
      "Finished epoch 146, latest loss -0.01246500015258789\n",
      "Finished epoch 147, latest loss -0.00796651840209961\n",
      "Finished epoch 148, latest loss -0.0063397884368896484\n",
      "Finished epoch 149, latest loss -0.014365196228027344\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "    \n",
    "model_RQ = network()\n",
    "\n",
    "loss_fn_RQ = MMDLoss(kernel=RQ())\n",
    "optimizer_RQ = optim.RMSprop(model_RQ.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 150 \n",
    "batch_size = 400 \n",
    "\n",
    "#training loop\n",
    "for epoch in range(n_epochs):\n",
    "    #shuffle training data\n",
    "    shuffle = torch.randperm(len(y))\n",
    "    y = y[shuffle]\n",
    "    X_input = X_input[shuffle]\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        Xbatch = X_input[i:i+batch_size] #predictors\n",
    "        x = np.random.uniform(-0.5,0.5,batch_size*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(batch_size, N_input)\n",
    "        X_model = torch.column_stack([Xbatch,x]) #model inputs\n",
    "        y_pred = model_RQ(X_model) #generated data\n",
    "        ybatch = y[i:i+batch_size] #real data\n",
    "        pred = torch.column_stack([Xbatch,y_pred])\n",
    "        real = torch.column_stack([Xbatch,ybatch])\n",
    "        loss = loss_fn_RQ(pred, real)\n",
    "        optimizer_RQ.zero_grad() #reset gradient\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer_RQ.step() #optimizer iteration\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train energy distance network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.028338313102722168\n",
      "Finished epoch 1, latest loss 0.006511688232421875\n",
      "Finished epoch 2, latest loss 0.022187113761901855\n",
      "Finished epoch 3, latest loss 0.006775021553039551\n",
      "Finished epoch 4, latest loss 0.014114737510681152\n",
      "Finished epoch 5, latest loss 0.0011254549026489258\n",
      "Finished epoch 6, latest loss 0.019311070442199707\n",
      "Finished epoch 7, latest loss 0.005970358848571777\n",
      "Finished epoch 8, latest loss -0.0028508901596069336\n",
      "Finished epoch 9, latest loss -0.0014647245407104492\n",
      "Finished epoch 10, latest loss -0.0015331506729125977\n",
      "Finished epoch 11, latest loss 0.009328126907348633\n",
      "Finished epoch 12, latest loss 0.0104827880859375\n",
      "Finished epoch 13, latest loss -0.003949403762817383\n",
      "Finished epoch 14, latest loss -0.0037376880645751953\n",
      "Finished epoch 15, latest loss 0.018416881561279297\n",
      "Finished epoch 16, latest loss -0.004198789596557617\n",
      "Finished epoch 17, latest loss -0.001356959342956543\n",
      "Finished epoch 18, latest loss -0.003651261329650879\n",
      "Finished epoch 19, latest loss -0.003014206886291504\n",
      "Finished epoch 20, latest loss -0.0034475326538085938\n",
      "Finished epoch 21, latest loss -0.004106640815734863\n",
      "Finished epoch 22, latest loss -0.0017589330673217773\n",
      "Finished epoch 23, latest loss -0.001452326774597168\n",
      "Finished epoch 24, latest loss 0.0006951093673706055\n",
      "Finished epoch 25, latest loss -0.002312183380126953\n",
      "Finished epoch 26, latest loss 0.002514481544494629\n",
      "Finished epoch 27, latest loss -0.001097559928894043\n",
      "Finished epoch 28, latest loss -0.0019515752792358398\n",
      "Finished epoch 29, latest loss -0.004385709762573242\n",
      "Finished epoch 30, latest loss 0.0025824308395385742\n",
      "Finished epoch 31, latest loss -0.0037713050842285156\n",
      "Finished epoch 32, latest loss -0.00383150577545166\n",
      "Finished epoch 33, latest loss -0.004805445671081543\n",
      "Finished epoch 34, latest loss -0.0027539730072021484\n",
      "Finished epoch 35, latest loss -0.0033975839614868164\n",
      "Finished epoch 36, latest loss -0.0032500028610229492\n",
      "Finished epoch 37, latest loss -0.0015990734100341797\n",
      "Finished epoch 38, latest loss 0.0075702667236328125\n",
      "Finished epoch 39, latest loss -0.0037717819213867188\n",
      "Finished epoch 40, latest loss -0.004067063331604004\n",
      "Finished epoch 41, latest loss -0.004227995872497559\n",
      "Finished epoch 42, latest loss 0.004952192306518555\n",
      "Finished epoch 43, latest loss -0.0040285587310791016\n",
      "Finished epoch 44, latest loss -0.0027725696563720703\n",
      "Finished epoch 45, latest loss 0.015132427215576172\n",
      "Finished epoch 46, latest loss -0.004405617713928223\n",
      "Finished epoch 47, latest loss -0.002849102020263672\n",
      "Finished epoch 48, latest loss -0.002634406089782715\n",
      "Finished epoch 49, latest loss 0.004153132438659668\n",
      "Finished epoch 50, latest loss -0.005064249038696289\n",
      "Finished epoch 51, latest loss -0.004553318023681641\n",
      "Finished epoch 52, latest loss -0.004473567008972168\n",
      "Finished epoch 53, latest loss -0.002803206443786621\n",
      "Finished epoch 54, latest loss -0.00430452823638916\n",
      "Finished epoch 55, latest loss -0.0040302276611328125\n",
      "Finished epoch 56, latest loss -0.0007365942001342773\n",
      "Finished epoch 57, latest loss -0.002763032913208008\n",
      "Finished epoch 58, latest loss -0.002682805061340332\n",
      "Finished epoch 59, latest loss -0.0023494958877563477\n",
      "Finished epoch 60, latest loss -0.00473940372467041\n",
      "Finished epoch 61, latest loss -0.004960179328918457\n",
      "Finished epoch 62, latest loss -0.003542184829711914\n",
      "Finished epoch 63, latest loss 0.005591392517089844\n",
      "Finished epoch 64, latest loss -0.0025821924209594727\n",
      "Finished epoch 65, latest loss -0.005271792411804199\n",
      "Finished epoch 66, latest loss -0.0005049705505371094\n",
      "Finished epoch 67, latest loss -0.0034140348434448242\n",
      "Finished epoch 68, latest loss 0.0065765380859375\n",
      "Finished epoch 69, latest loss -0.0032159090042114258\n",
      "Finished epoch 70, latest loss -0.0038372278213500977\n",
      "Finished epoch 71, latest loss 0.00218963623046875\n",
      "Finished epoch 72, latest loss 0.0013551712036132812\n",
      "Finished epoch 73, latest loss -0.004973769187927246\n",
      "Finished epoch 74, latest loss -0.0037146806716918945\n",
      "Finished epoch 75, latest loss -0.0036919116973876953\n",
      "Finished epoch 76, latest loss -0.004902482032775879\n",
      "Finished epoch 77, latest loss -0.004169464111328125\n",
      "Finished epoch 78, latest loss -0.004664301872253418\n",
      "Finished epoch 79, latest loss -0.0020357370376586914\n",
      "Finished epoch 80, latest loss -0.0048596858978271484\n",
      "Finished epoch 81, latest loss -0.003097057342529297\n",
      "Finished epoch 82, latest loss -0.004691123962402344\n",
      "Finished epoch 83, latest loss -0.004136085510253906\n",
      "Finished epoch 84, latest loss -0.004238486289978027\n",
      "Finished epoch 85, latest loss -0.004933953285217285\n",
      "Finished epoch 86, latest loss 0.0004074573516845703\n",
      "Finished epoch 87, latest loss -0.004142045974731445\n",
      "Finished epoch 88, latest loss -0.0002955198287963867\n",
      "Finished epoch 89, latest loss -0.0029352903366088867\n",
      "Finished epoch 90, latest loss -0.004670262336730957\n",
      "Finished epoch 91, latest loss -0.0008327960968017578\n",
      "Finished epoch 92, latest loss -0.004065036773681641\n",
      "Finished epoch 93, latest loss -0.0019925832748413086\n",
      "Finished epoch 94, latest loss -0.0007318258285522461\n",
      "Finished epoch 95, latest loss 0.01331937313079834\n",
      "Finished epoch 96, latest loss -0.004570960998535156\n",
      "Finished epoch 97, latest loss -0.004781842231750488\n",
      "Finished epoch 98, latest loss 0.012763261795043945\n",
      "Finished epoch 99, latest loss -0.00426936149597168\n",
      "Finished epoch 100, latest loss -0.002554774284362793\n",
      "Finished epoch 101, latest loss -0.003256678581237793\n",
      "Finished epoch 102, latest loss -0.005275368690490723\n",
      "Finished epoch 103, latest loss -0.004788517951965332\n",
      "Finished epoch 104, latest loss 0.00022554397583007812\n",
      "Finished epoch 105, latest loss 0.0032273530960083008\n",
      "Finished epoch 106, latest loss -0.005261898040771484\n",
      "Finished epoch 107, latest loss -0.003791213035583496\n",
      "Finished epoch 108, latest loss -0.0030012130737304688\n",
      "Finished epoch 109, latest loss -0.0038105249404907227\n",
      "Finished epoch 110, latest loss -0.0016666650772094727\n",
      "Finished epoch 111, latest loss -0.0035370588302612305\n",
      "Finished epoch 112, latest loss -0.003888249397277832\n",
      "Finished epoch 113, latest loss -0.0031404495239257812\n",
      "Finished epoch 114, latest loss -0.003847837448120117\n",
      "Finished epoch 115, latest loss -0.0043593645095825195\n",
      "Finished epoch 116, latest loss -0.004121899604797363\n",
      "Finished epoch 117, latest loss -0.004568815231323242\n",
      "Finished epoch 118, latest loss 0.0017107725143432617\n",
      "Finished epoch 119, latest loss 0.0001461505889892578\n",
      "Finished epoch 120, latest loss -0.002264261245727539\n",
      "Finished epoch 121, latest loss -0.004817485809326172\n",
      "Finished epoch 122, latest loss -0.0022826194763183594\n",
      "Finished epoch 123, latest loss -0.00394439697265625\n",
      "Finished epoch 124, latest loss 0.0025676488876342773\n",
      "Finished epoch 125, latest loss -0.004790782928466797\n",
      "Finished epoch 126, latest loss -0.00278627872467041\n",
      "Finished epoch 127, latest loss -0.0012354850769042969\n",
      "Finished epoch 128, latest loss 0.002936244010925293\n",
      "Finished epoch 129, latest loss -0.0046416521072387695\n",
      "Finished epoch 130, latest loss -0.0008858442306518555\n",
      "Finished epoch 131, latest loss -0.0014727115631103516\n",
      "Finished epoch 132, latest loss -0.004588603973388672\n",
      "Finished epoch 133, latest loss 0.0008455514907836914\n",
      "Finished epoch 134, latest loss -0.0004019737243652344\n",
      "Finished epoch 135, latest loss -0.004575610160827637\n",
      "Finished epoch 136, latest loss -0.001135706901550293\n",
      "Finished epoch 137, latest loss -0.00473785400390625\n",
      "Finished epoch 138, latest loss -0.003827214241027832\n",
      "Finished epoch 139, latest loss -0.0036562681198120117\n",
      "Finished epoch 140, latest loss -0.0042514801025390625\n",
      "Finished epoch 141, latest loss -0.0007815361022949219\n",
      "Finished epoch 142, latest loss 0.0029439926147460938\n",
      "Finished epoch 143, latest loss -0.0038940906524658203\n",
      "Finished epoch 144, latest loss -0.0012640953063964844\n",
      "Finished epoch 145, latest loss -0.004443168640136719\n",
      "Finished epoch 146, latest loss -0.003525853157043457\n",
      "Finished epoch 147, latest loss -0.003013014793395996\n",
      "Finished epoch 148, latest loss -0.004290580749511719\n",
      "Finished epoch 149, latest loss -0.003342270851135254\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "    \n",
    "model_ED = network()\n",
    "\n",
    "loss_fn_ED = EnergyDistance()\n",
    "optimizer_ED = optim.RMSprop(model_ED.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 150 \n",
    "batch_size = 400 \n",
    "\n",
    "#training loop\n",
    "for epoch in range(n_epochs):\n",
    "    #shuffle training data:\n",
    "    shuffle = torch.randperm(len(y))\n",
    "    y = y[shuffle]\n",
    "    X_input = X_input[shuffle]\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        Xbatch = X_input[i:i+batch_size] #predictors\n",
    "        x = np.random.uniform(-0.5,0.5,batch_size*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(batch_size, N_input)\n",
    "        X_model = torch.column_stack([Xbatch,x]) #model inputs\n",
    "        y_pred = model_ED(X_model) #generated data\n",
    "        ybatch = y[i:i+batch_size] #real data\n",
    "        pred = torch.column_stack([Xbatch,y_pred])\n",
    "        real = torch.column_stack([Xbatch,ybatch])\n",
    "        loss = loss_fn_ED(pred, real)\n",
    "        optimizer_ED.zero_grad() #reset gradient\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer_ED.step() #optimizer iteration\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the four models by generating 1000 test data for multiple sets of predictors..\n",
    "For the generated sample distributions, we compute MSE for mean and quantiles, mean MMDs and energy distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD network with RBF kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0.1\n",
      "0.15000000000000002\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35000000000000003\n",
      "0.4\n",
      "0.45\n",
      "0.5\n",
      "0.55\n",
      "0.6000000000000001\n",
      "0.6500000000000001\n",
      "0.7000000000000001\n",
      "0.7500000000000001\n",
      "0.8\n",
      "0.8500000000000001\n",
      "0.9000000000000001\n",
      "0.9500000000000001\n",
      "MSE of means: 0.04332397266763042\n",
      "MSE of 0.9 quantiles: 0.36617931277134896\n",
      "MSE of 0.1 quantiles: 0.009880471393814374\n",
      "MMD with RBF kernel: 0.007706479635089636\n",
      "MMD with Laplacian kernel: 0.11768161505460739\n",
      "MMD with RQ kernel: 0.013616926036775112\n",
      "Energy distance: 0.0071420310996472836\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "MSE_means = []\n",
    "MSE_quantiles = []\n",
    "MSE_quantiles10 = []\n",
    "MMD_RBF = []\n",
    "MMD_Laplacian = []\n",
    "MMD_RQ = []\n",
    "ED = []\n",
    "\n",
    "for i in np.arange(0.05,1,0.05): #x_1\n",
    "    for j in np.arange(0.05,1,0.05): #x_2\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x]) #model inputs for predictors i and j\n",
    "        with torch.no_grad(): #do not update gradient\n",
    "            y_sample = model(X_predict) #model outputs : generated data\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j) #real distribution\n",
    "        y_compare = (i + j)*np.exp(np.random.normal(0,sigma,1000)) #samples from the real distribution\n",
    "        y_compare = torch.tensor(y_compare, dtype=torch.float32).reshape(-1, 1)\n",
    "        #MMDs between real and generated samples:\n",
    "        MMD_RBF.append(loss_fn(y_sample,y_compare))\n",
    "        MMD_Laplacian.append(loss_fn_Laplacian(y_sample,y_compare))\n",
    "        MMD_RQ.append(loss_fn_RQ(y_sample,y_compare))\n",
    "        #ED between real and generated samples:\n",
    "        ED.append(loss_fn_ED(y_sample,y_compare))\n",
    "        #MSEs for distribution means and quantiles:\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        MSE_means.append((mylognorm.mean() - np.mean(y_sample))**2)\n",
    "        MSE_quantiles.append((mylognorm.ppf(0.9)-np.quantile(y_sample,0.9))**2)\n",
    "        MSE_quantiles10.append((mylognorm.ppf(0.1)-np.quantile(y_sample,0.1))**2)\n",
    "    print(i)\n",
    "\n",
    "print(f'MSE of means: {np.mean(MSE_means)}')\n",
    "print(f'MSE of 0.9 quantiles: {np.mean(MSE_quantiles)}')\n",
    "print(f'MSE of 0.1 quantiles: {np.mean(MSE_quantiles10)}')\n",
    "print(f'MMD with RBF kernel: {np.mean(MMD_RBF)}')\n",
    "print(f'MMD with Laplacian kernel: {np.mean(MMD_Laplacian)}')\n",
    "print(f'MMD with RQ kernel: {np.mean(MMD_RQ)}')\n",
    "print(f'Energy distance: {np.mean(ED)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD network with laplacian kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0.1\n",
      "0.15000000000000002\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35000000000000003\n",
      "0.4\n",
      "0.45\n",
      "0.5\n",
      "0.55\n",
      "0.6000000000000001\n",
      "0.6500000000000001\n",
      "0.7000000000000001\n",
      "0.7500000000000001\n",
      "0.8\n",
      "0.8500000000000001\n",
      "0.9000000000000001\n",
      "0.9500000000000001\n",
      "MSE of means: 0.01883383253864098\n",
      "MSE of 0.9 quantiles: 0.1784634286517737\n",
      "MSE of 0.1 quantiles: 0.003833887418238768\n",
      "MMD with RBF kernel: 0.006646234076470137\n",
      "MMD with Laplacian kernel: 0.01454382948577404\n",
      "MMD with RQ kernel: 0.011285052634775639\n",
      "Energy distance: 0.0036145795602351427\n"
     ]
    }
   ],
   "source": [
    "#same code as for RBF kernel except change model to model_Laplacian\n",
    "np.random.seed(3)\n",
    "\n",
    "MSE_means = []\n",
    "MSE_quantiles = []\n",
    "MSE_quantiles10 = []\n",
    "MMD_RBF = []\n",
    "MMD_Laplacian = []\n",
    "MMD_RQ = []\n",
    "ED = []\n",
    "\n",
    "for i in np.arange(0.05,1,0.05):\n",
    "    for j in np.arange(0.05,1,0.05):\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x])\n",
    "        with torch.no_grad(): \n",
    "            y_sample = model_Laplacian(X_predict)\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j)\n",
    "        y_compare = (i + j)*np.exp(np.random.normal(0,sigma,1000))\n",
    "        y_compare = torch.tensor(y_compare, dtype=torch.float32).reshape(-1, 1)\n",
    "        MMD_RBF.append(loss_fn(y_sample,y_compare))\n",
    "        MMD_Laplacian.append(loss_fn_Laplacian(y_sample,y_compare))\n",
    "        MMD_RQ.append(loss_fn_RQ(y_sample,y_compare))\n",
    "        ED.append(loss_fn_ED(y_sample,y_compare))\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        MSE_means.append((mylognorm.mean() - np.mean(y_sample))**2)\n",
    "        MSE_quantiles.append((mylognorm.ppf(0.9)-np.quantile(y_sample,0.9))**2)\n",
    "        MSE_quantiles10.append((mylognorm.ppf(0.1)-np.quantile(y_sample,0.1))**2)\n",
    "    print(i)\n",
    "\n",
    "print(f'MSE of means: {np.mean(MSE_means)}')\n",
    "print(f'MSE of 0.9 quantiles: {np.mean(MSE_quantiles)}')\n",
    "print(f'MSE of 0.1 quantiles: {np.mean(MSE_quantiles10)}')\n",
    "print(f'MMD with RBF kernel: {np.mean(MMD_RBF)}')\n",
    "print(f'MMD with Laplacian kernel: {np.mean(MMD_Laplacian)}')\n",
    "print(f'MMD with RQ kernel: {np.mean(MMD_RQ)}')\n",
    "print(f'Energy distance: {np.mean(ED)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD network with RQ kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0.1\n",
      "0.15000000000000002\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35000000000000003\n",
      "0.4\n",
      "0.45\n",
      "0.5\n",
      "0.55\n",
      "0.6000000000000001\n",
      "0.6500000000000001\n",
      "0.7000000000000001\n",
      "0.7500000000000001\n",
      "0.8\n",
      "0.8500000000000001\n",
      "0.9000000000000001\n",
      "0.9500000000000001\n",
      "MSE of means: 0.02322326900558846\n",
      "MSE of 0.9 quantiles: 0.2162351978674884\n",
      "MSE of 0.1 quantiles: 0.010742446300704598\n",
      "MMD with RBF kernel: 0.007385520730167627\n",
      "MMD with Laplacian kernel: 0.12586864829063416\n",
      "MMD with RQ kernel: 0.012231179513037205\n",
      "Energy distance: 0.005839320831000805\n"
     ]
    }
   ],
   "source": [
    "#same code as for RBF kernel except change model to model_RQ\n",
    "np.random.seed(3)\n",
    "\n",
    "MSE_means = []\n",
    "MSE_quantiles = []\n",
    "MSE_quantiles10 = []\n",
    "MMD_RBF = []\n",
    "MMD_Laplacian = []\n",
    "MMD_RQ = []\n",
    "ED = []\n",
    "\n",
    "for i in np.arange(0.05,1,0.05):\n",
    "    for j in np.arange(0.05,1,0.05):\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x])\n",
    "        with torch.no_grad(): \n",
    "            y_sample = model_RQ(X_predict)\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j)\n",
    "        y_compare = (i + j)*np.exp(np.random.normal(0,sigma,1000))\n",
    "        y_compare = torch.tensor(y_compare, dtype=torch.float32).reshape(-1, 1)\n",
    "        MMD_RBF.append(loss_fn(y_sample,y_compare))\n",
    "        MMD_Laplacian.append(loss_fn_Laplacian(y_sample,y_compare))\n",
    "        MMD_RQ.append(loss_fn_RQ(y_sample,y_compare))\n",
    "        ED.append(loss_fn_ED(y_sample,y_compare))\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        MSE_means.append((mylognorm.mean() - np.mean(y_sample))**2)\n",
    "        MSE_quantiles.append((mylognorm.ppf(0.9)-np.quantile(y_sample,0.9))**2)\n",
    "        MSE_quantiles10.append((mylognorm.ppf(0.1)-np.quantile(y_sample,0.1))**2)\n",
    "    print(i)\n",
    "\n",
    "print(f'MSE of means: {np.mean(MSE_means)}')\n",
    "print(f'MSE of 0.9 quantiles: {np.mean(MSE_quantiles)}')\n",
    "print(f'MSE of 0.1 quantiles: {np.mean(MSE_quantiles10)}')\n",
    "print(f'MMD with RBF kernel: {np.mean(MMD_RBF)}')\n",
    "print(f'MMD with Laplacian kernel: {np.mean(MMD_Laplacian)}')\n",
    "print(f'MMD with RQ kernel: {np.mean(MMD_RQ)}')\n",
    "print(f'Energy distance: {np.mean(ED)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy distance network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0.1\n",
      "0.15000000000000002\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35000000000000003\n",
      "0.4\n",
      "0.45\n",
      "0.5\n",
      "0.55\n",
      "0.6000000000000001\n",
      "0.6500000000000001\n",
      "0.7000000000000001\n",
      "0.7500000000000001\n",
      "0.8\n",
      "0.8500000000000001\n",
      "0.9000000000000001\n",
      "0.9500000000000001\n",
      "MSE of means: 0.04184866767976244\n",
      "MSE of 0.9 quantiles: 0.3441355086012315\n",
      "MSE of 0.1 quantiles: 0.01193109867280134\n",
      "MMD with RBF kernel: 0.009042109362781048\n",
      "MMD with Laplacian kernel: 0.1604633331298828\n",
      "MMD with RQ kernel: 0.014907419681549072\n",
      "Energy distance: 0.008299540728330612\n"
     ]
    }
   ],
   "source": [
    "#same code as for RBF kernel except change model to model_ED\n",
    "np.random.seed(3)\n",
    "\n",
    "MSE_means = []\n",
    "MSE_quantiles = []\n",
    "MSE_quantiles10 = []\n",
    "MMD_RBF = []\n",
    "MMD_Laplacian = []\n",
    "MMD_RQ = []\n",
    "ED = []\n",
    "\n",
    "for i in np.arange(0.05,1,0.05):\n",
    "    for j in np.arange(0.05,1,0.05):\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x])\n",
    "        with torch.no_grad(): \n",
    "            y_sample = model_ED(X_predict)\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j) \n",
    "        y_compare = (i + j)*np.exp(np.random.normal(0,sigma,1000))\n",
    "        y_compare = torch.tensor(y_compare, dtype=torch.float32).reshape(-1, 1)\n",
    "        MMD_RBF.append(loss_fn(y_sample,y_compare))\n",
    "        MMD_Laplacian.append(loss_fn_Laplacian(y_sample,y_compare))\n",
    "        MMD_RQ.append(loss_fn_RQ(y_sample,y_compare))\n",
    "        ED.append(loss_fn_ED(y_sample,y_compare))\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        MSE_means.append((mylognorm.mean() - np.mean(y_sample))**2)\n",
    "        MSE_quantiles.append((mylognorm.ppf(0.9)-np.quantile(y_sample,0.9))**2)\n",
    "        MSE_quantiles10.append((mylognorm.ppf(0.1)-np.quantile(y_sample,0.1))**2)\n",
    "    print(i)\n",
    "\n",
    "print(f'MSE of means: {np.mean(MSE_means)}')\n",
    "print(f'MSE of 0.9 quantiles: {np.mean(MSE_quantiles)}')\n",
    "print(f'MSE of 0.1 quantiles: {np.mean(MSE_quantiles10)}')\n",
    "print(f'MMD with RBF kernel: {np.mean(MMD_RBF)}')\n",
    "print(f'MMD with Laplacian kernel: {np.mean(MMD_Laplacian)}')\n",
    "print(f'MMD with RQ kernel: {np.mean(MMD_RQ)}')\n",
    "print(f'Energy distance: {np.mean(ED)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram and Q-Q plot for specific predictors, can change predictors and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.612509   0.75887036 1.4037673  0.67485327 1.0750144  0.7138247\n",
      " 0.7764564  1.1580563  1.1554803 ]\n",
      "Real quantiles: [0.61671486 0.7        0.90985076 1.3285669  2.24005181 3.28196133]\n",
      "Sample quantiles: [0.63433014 0.71308103 0.91488107 1.35662066 3.32042624 6.78156373]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7932039171467784, 0.17870096846606937, 1.7501896550697178, 5.898445673784778)\n",
      "0.8433116\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "x = np.random.uniform(-0.5,0.5,10000*N_input)\n",
    "x = torch.tensor(x, dtype=torch.float32).reshape(10000, N_input)\n",
    "X_predict = torch.tensor([0.4,0.3]*10000, dtype=torch.float32).reshape(10000,2)\n",
    "X_predict = (X_predict) / X_stds\n",
    "X_predict = torch.column_stack([X_predict,x]) #model inputs for x_1=0.4 and x_2=0.3\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_sample = model_Laplacian(X_predict) #model outputs\n",
    "\n",
    "y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "print(y_sample[1:10]) #first 10 generated samples\n",
    "\n",
    "#real distribution\n",
    "mylognorm = stats.lognorm(s = 0.5, scale = 0.7)\n",
    "\n",
    "#quantiles\n",
    "print(f'Real quantiles: {mylognorm.ppf([0.4,0.5,0.7,0.9,0.99,0.999])}')\n",
    "print(f'Sample quantiles: {np.quantile(y_sample, [0.4,0.5,0.7,0.9,0.99,0.999])}')\n",
    "\n",
    "#histogram\n",
    "plt.hist(y_sample, bins = 40, density=True) \n",
    "x_axis = np.arange(-1, 70, 0.001) \n",
    "plt.plot(x_axis, mylognorm.pdf(x_axis))\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlim(-1, 6)\n",
    "plt.show()\n",
    "\n",
    "#qq plot\n",
    "sm.qqplot(y_sample, mylognorm, line = '45')\n",
    "plt.show()\n",
    "\n",
    "print(mylognorm.stats(moments='mvsk')) #mean, var, skew, kurt for real distribution\n",
    "print(np.mean(y_sample)) #sample mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do generated sample distributions have lighter or heavier tails than the real distributions? \n",
    "We compare sample quantiles and real quantiles for x1 < 0.5 and x1 > 0.5 seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "# x_1 < 0.5\n",
    "np.random.seed(3)\n",
    "\n",
    "n = 0\n",
    "N_quantile_higher = 0 #number of cases when the generated distribution has larger high quantile (heavier tail) than the real distribution\n",
    "\n",
    "for i in np.arange(0.05,0.5,0.05): #x_1\n",
    "    for j in np.arange(0.05,1,0.05): #x_2\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x]) #model inputs\n",
    "        with torch.no_grad():\n",
    "            y_sample = model_Laplacian(X_predict) #model outputs\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j) #real distribution\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        if np.quantile(y_sample, 0.99) > mylognorm.ppf(0.99) : N_quantile_higher += 1 #compare 99% and 99.9% quantiles\n",
    "        n+=1\n",
    "\n",
    "print(N_quantile_higher/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605263157894737\n"
     ]
    }
   ],
   "source": [
    "# 0.3 < x_1 < 0.5\n",
    "np.random.seed(3)\n",
    "\n",
    "n = 0\n",
    "N_quantile_higher = 0  #number of cases when the generated distribution has larger high quantile (heavier tail) than the real distribution\n",
    "\n",
    "for i in np.arange(0.3,0.5,0.05): #x_1\n",
    "    for j in np.arange(0.05,1,0.05): #x_2\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x]) #model inputs\n",
    "        with torch.no_grad():\n",
    "            y_sample = model_Laplacian(X_predict) #model outputs\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j) #real distribution\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        if np.quantile(y_sample, 0.999) > mylognorm.ppf(0.999) : N_quantile_higher += 1 #compare 99% and 99.9% quantiles\n",
    "        n+=1\n",
    "\n",
    "print(N_quantile_higher/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23157894736842105\n"
     ]
    }
   ],
   "source": [
    "# x_1 < 0.3\n",
    "np.random.seed(3)\n",
    "\n",
    "n = 0\n",
    "N_quantile_higher = 0 #number of cases when the generated distribution has larger high quantile (heavier tail) than the real distribution\n",
    "\n",
    "for i in np.arange(0.05,0.3,0.05): #x_1\n",
    "    for j in np.arange(0.05,1,0.05): #x_2\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x]) #model inputs\n",
    "        with torch.no_grad(): \n",
    "            y_sample = model_Laplacian(X_predict) #model outputs\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j) #real distribution\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        if np.quantile(y_sample, 0.999) > mylognorm.ppf(0.999) : N_quantile_higher += 1 #compare 99% and 99.9% quantiles\n",
    "        n+=1\n",
    "\n",
    "print(N_quantile_higher/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# x_1 > 0.5\n",
    "np.random.seed(3)\n",
    "\n",
    "n = 0\n",
    "N_quantile_lower = 0  #number of cases when the generated distribution has smaller high quantile (lighter tail) than the real distribution\n",
    "\n",
    "for i in np.arange(0.55,1,0.05):\n",
    "    for j in np.arange(0.05,1,0.05):\n",
    "        x = np.random.uniform(-0.5,0.5,1000*N_input)\n",
    "        x = torch.tensor(x, dtype=torch.float32).reshape(1000, N_input)\n",
    "        X_predict = torch.tensor([i,j]*1000, dtype=torch.float32).reshape(1000,2)\n",
    "        X_predict = (X_predict) / X_stds\n",
    "        X_predict = torch.column_stack([X_predict,x]) #model inputs\n",
    "        with torch.no_grad():\n",
    "            y_sample = model_Laplacian(X_predict) #model outputs\n",
    "        if i > 0.5: sigma = 1\n",
    "        else: sigma = 0.5\n",
    "        mylognorm = stats.lognorm(s = sigma, scale = i+j) #real distribution\n",
    "        y_sample = y_sample.reshape(1,-1).numpy()[0]\n",
    "        if np.quantile(y_sample, 0.999) < mylognorm.ppf(0.999) : N_quantile_lower += 1 #compare 99% and 99.9% quantiles\n",
    "        n+=1\n",
    "\n",
    "print(N_quantile_lower/n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
